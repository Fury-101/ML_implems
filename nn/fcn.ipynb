{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (1.26.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (from matplotlib) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in /home/vinay/Code/ML/implems/.conda/lib/python3.11/site-packages (4.66.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def gradSigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "# def relu(x):\n",
    "#     return (abs(x) + x) / 2\n",
    "\n",
    "# def input(x):\n",
    "#     return x\n",
    "\n",
    "import random\n",
    "\n",
    "class NN():\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def forward(self, a):\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    def train(self, x_train, y_train, epochs, mini_batch_size, lr):\n",
    "\n",
    "        for j in range(epochs):\n",
    "            p = np.random.permutation(len(x_train))\n",
    "            x_train = x_train[p]\n",
    "            y_train = y_train[p]\n",
    "            \n",
    "            x_batches = [\n",
    "                x_train[k:k+mini_batch_size]\n",
    "                for k in range(0, len(x_train), mini_batch_size)]\n",
    "            \n",
    "            y_batches = [\n",
    "                y_train[k:k+mini_batch_size]\n",
    "                for k in range(0, len(y_train), mini_batch_size)]\n",
    "            \n",
    "            for x, y in tqdm(list(zip(x_batches, y_batches))):\n",
    "                self.handle_batch(x, y, lr)\n",
    "\n",
    "            print(\"Epoch {} complete\".format(j+1))\n",
    "\n",
    "    def handle_batch(self, x, y, lr):\n",
    "        dCdbfull = [np.zeros(b.shape) for b in self.biases]\n",
    "        dCdWfull = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        for x_sample, y_sample in zip(x, y):\n",
    "            dCdb, dCdW = self.backprop(x_sample, y_sample)\n",
    "            dCdbfull = [nb+dnb for nb, dnb in zip(dCdbfull, dCdb)]\n",
    "            dCdWfull = [nw+dnw for nw, dnw in zip(dCdWfull, dCdW)]\n",
    "            \n",
    "        self.weights = [w - (lr/len(x_sample))*nw\n",
    "                        for w, nw in zip(self.weights, dCdWfull)]\n",
    "        self.biases = [b - (lr/len(x_sample))*nb\n",
    "                       for b, nb in zip(self.biases, dCdbfull)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        a = x\n",
    "        a_history = [x]\n",
    "        z_history = [] \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, a) + b\n",
    "            z_history.append(z)\n",
    "            a = sigmoid(z)\n",
    "            a_history.append(a)\n",
    "            \n",
    "        errorL = (a_history[-1] - y) * gradSigmoid(z_history[-1])\n",
    "        \n",
    "        dCdW = [np.zeros(w.shape) for w in self.weights]\n",
    "        dCdb = [np.zeros(b.shape) for b in self.biases]\n",
    "\n",
    "        dCdW[-1] = np.dot(errorL, a_history[-2].transpose())\n",
    "        dCdb[-1] = errorL\n",
    "        \n",
    "        # print(\"Len z history:\"+str(len(z_history)))  2\n",
    "        # print(\"Len weights:\"+str(len(self.weights))) 2\n",
    "        # print(\"Len a history:\"+str(len(a_history)))  3\n",
    "        # print()\n",
    "        for l in range(self.num_layers-1, 1, -1):\n",
    "            z = z_history[l-2]\n",
    "            sp = gradSigmoid(z)\n",
    "            errorL = np.dot(self.weights[l-1].transpose(), errorL) * sp\n",
    "            dCdW[-l] = np.dot(errorL, a_history[l-2].transpose())\n",
    "            dCdb[-l] = errorL\n",
    "        return (dCdb, dCdW)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(np.argmax(self.forward(x)), np.argmax(y))\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results) / len(test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
